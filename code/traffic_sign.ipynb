{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Speed limit (20km/h)' 'Speed limit (30km/h)' 'Speed limit (50km/h)'\n",
      " 'Speed limit (60km/h)' 'Speed limit (70km/h)' 'Speed limit (80km/h)'\n",
      " 'End of speed limit (80km/h)' 'Speed limit (100km/h)'\n",
      " 'Speed limit (120km/h)' 'No passing'\n",
      " 'No passing for vechiles over 3.5 metric tons'\n",
      " 'Right-of-way at the next intersection' 'Priority road' 'Yield' 'Stop'\n",
      " 'No vechiles' 'Vechiles over 3.5 metric tons prohibited' 'No entry'\n",
      " 'General caution' 'Dangerous curve to the left'\n",
      " 'Dangerous curve to the right' 'Double curve' 'Bumpy road'\n",
      " 'Slippery road' 'Road narrows on the right' 'Road work' 'Traffic signals'\n",
      " 'Pedestrians' 'Children crossing' 'Bicycles crossing'\n",
      " 'Beware of ice/snow' 'Wild animals crossing'\n",
      " 'End of all speed and passing limits' 'Turn right ahead'\n",
      " 'Turn left ahead' 'Ahead only' 'Go straight or right'\n",
      " 'Go straight or left' 'Keep right' 'Keep left' 'Roundabout mandatory'\n",
      " 'End of no passing' 'End of no passing by vechiles over 3.5 metric tons']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=[Yield] id=13 conf=1.0\n",
      "No Draw: label=[Yield] id=13 conf=1.0\n",
      "label=[Yield] id=13 conf=1.0\n",
      "No Draw: label=[Yield] id=13 conf=1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "#brew install opencv\n",
    "#pip install opencv-python\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "#pip install moviepy\n",
    "#pip install requests\n",
    "from moviepy.editor import *\n",
    "from matplotlib import pyplot as plt \n",
    "import keras\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "\n",
    "\n",
    "infile=\"../picture/v.mp4\"\n",
    "outfile=\"../picture/v-output.mp4\"\n",
    "\n",
    "'''\n",
    "Code adapted from:\n",
    "https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "\n",
    "'''\n",
    "\n",
    "IMG_SHAPE=[32,32,3]\n",
    "INPUT_SHAPE=[1,32,32,3]\n",
    "L2_LAMBDA = 0.0001   \n",
    "WEIGTHS_PATH=\"../doc/weights_mltscl_dataaug.hdf5\"\n",
    "OUTPUT_DIM=43\n",
    "LR = 0.0001\n",
    "CONF_THRES=0.6\n",
    "\n",
    "# Labels of circlur signs\n",
    "cir_cls = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 16,\n",
    "           17, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]\n",
    "\n",
    "signnames = read_csv(\"../doc/signnames.csv\").values[:, 1]\n",
    "\n",
    "print(signnames)\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Compute softmax values for each sets of scores in x.\n",
    "    Ref: https://stackoverflow.com/questions/34968722/softmax-function-python\n",
    "    \"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def build_mltscl():\n",
    "    \"\"\"\n",
    "    Build multiscale CNN. The last layer must be logits instead of softmax.\n",
    "    Return a compiled Keras model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Regularization\n",
    "    l2_reg = keras.regularizers.l2(L2_LAMBDA)\n",
    "\n",
    "    # Build model\n",
    "    inpt = keras.layers.Input(shape=IMG_SHAPE)\n",
    "    conv1 = keras.layers.Convolution2D(\n",
    "        32, (5, 5), padding='same', activation='relu')(inpt)\n",
    "    drop1 = keras.layers.Dropout(rate=0.1)(conv1)\n",
    "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(drop1)\n",
    "\n",
    "    conv2 = keras.layers.Convolution2D(\n",
    "        64, (5, 5), padding='same', activation='relu')(pool1)\n",
    "    drop2 = keras.layers.Dropout(rate=0.2)(conv2)\n",
    "    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(drop2)\n",
    "\n",
    "    conv3 = keras.layers.Convolution2D(\n",
    "        128, (5, 5), padding='same', activation='relu')(pool2)\n",
    "    drop3 = keras.layers.Dropout(rate=0.3)(conv3)\n",
    "    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(drop3)\n",
    "\n",
    "    pool4 = keras.layers.MaxPooling2D(pool_size=(4, 4))(pool1)\n",
    "    pool5 = keras.layers.MaxPooling2D(pool_size=(2, 2))(pool2)\n",
    "\n",
    "    flat1 = keras.layers.Flatten()(pool4)\n",
    "    flat2 = keras.layers.Flatten()(pool5)\n",
    "    flat3 = keras.layers.Flatten()(pool3)\n",
    "\n",
    "    merge = keras.layers.Concatenate(axis=-1)([flat1, flat2, flat3])\n",
    "    dense1 = keras.layers.Dense(1024, activation='relu',\n",
    "                                kernel_regularizer=l2_reg)(merge)\n",
    "    drop4 = keras.layers.Dropout(rate=0.5)(dense1)\n",
    "    output = keras.layers.Dense(\n",
    "        OUTPUT_DIM, activation=None, kernel_regularizer=l2_reg)(drop4)\n",
    "    model = keras.models.Model(inputs=inpt, outputs=output)\n",
    "\n",
    "    # Specify optimizer\n",
    "    adam = keras.optimizers.Adam(\n",
    "        lr=LR, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model=build_mltscl()\n",
    "model.load_weights(WEIGTHS_PATH)\n",
    "#model.summary()\n",
    "\n",
    "def rgb2gray(image):\n",
    "    \"\"\"Convert 3-channel RGB image into grayscale\"\"\"\n",
    "    if image.ndim == 3:\n",
    "        return (0.299 * image[:, :, 0] + 0.587 * image[:, :, 1] +\n",
    "                0.114 * image[:, :, 2])\n",
    "    elif image.ndim == 4:\n",
    "        return (0.299 * image[:, :, :, 0] + 0.587 * image[:, :, :, 1] +\n",
    "                0.114 * image[:, :, :, 2])\n",
    "\n",
    "#识别原型的交通牌\n",
    "def find_circles(img, mg_ratio=0.4, n_circles=1):\n",
    "    \"\"\"\n",
    "    Find circular objects and return bounding boxes in the format\n",
    "    [x1, y1, x2, y2]\n",
    "    \"\"\"\n",
    "\n",
    "    targetImg = np.copy(img)\n",
    "    targetImg = np.uint8(targetImg * 255)\n",
    "    # Apply Gaussian blur if needed\n",
    "    n = 13\n",
    "    targetImg = cv2.GaussianBlur(targetImg, (n, n), 0)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    grayImg = np.uint8(rgb2gray(targetImg))\n",
    "    #grayImg = targetImg\n",
    "    # param1 is canny threshold, param2 is circle accumulator threshold\n",
    "    # Set of parameters for GTSDB testing\n",
    "    # (because of different frame size and recording device)\n",
    "    # circles = cv2.HoughCircles(grayImg, cv2.HOUGH_GRADIENT, 1, 200,\n",
    "    #                            param1=60, param2=50, minRadius=5,\n",
    "    #                            maxRadius=100)\n",
    "    \n",
    "    #通过调节minRadius=20,maxRadius=250设置可以检测的车牌大小\n",
    "    circles = cv2.HoughCircles(grayImg, cv2.HOUGH_GRADIENT, 1, 200,\n",
    "                               param1=50, param2=30, minRadius=10,\n",
    "                               maxRadius=100)\n",
    "\n",
    "    bboxes = []\n",
    "    try:\n",
    "        cir = circles.astype(np.uint16)\n",
    "        for c in cir[0, :n_circles]:\n",
    "            r = int(c[2])\n",
    "            mg = int(r * mg_ratio)\n",
    "            bboxes.append([c[0] - r - mg, c[1] - r - mg,\n",
    "                           c[0] + r + mg, c[1] + r + mg])\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    except:\n",
    "        raise\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def draw_bb(img, bbox, color=(0, 1, 0)):\n",
    "    \"\"\"Draw bounding box\"\"\"\n",
    "    cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]),\n",
    "                  color, 2)\n",
    "    return img\n",
    "\n",
    "def crop_bb(img, bbox):\n",
    "    \"\"\"Crop image by specifying bounding box\"\"\"\n",
    "    bb = np.array(bbox)\n",
    "    bb = bb * (bb > 0)\n",
    "    return img[bb[1]:bb[3], bb[0]:bb[2], :]\n",
    "\n",
    "\n",
    "def demo():\n",
    "    \n",
    "    demo_file=\"../picture/traffic_sign.jpeg\"\n",
    "    #OpenCV读取的格式为BGR 需要转换成RGB进行展现\n",
    "    demo_img=cv2.imread(demo_file)\n",
    "    demo_img=cv2.cvtColor(demo_img, cv2.COLOR_BGR2RGB) \n",
    "    show_img=demo_img.copy()\n",
    "    plt.imshow(show_img) \n",
    "    plt.show() \n",
    "    \n",
    "    #归一化 非常重要\n",
    "    show_img=(show_img / 255.).astype(np.float32)\n",
    "    \n",
    "    bboxes = find_circles(show_img, mg_ratio=0.4, n_circles=3)\n",
    "    for bbox in bboxes:\n",
    "        crop = crop_bb(show_img, bbox)\n",
    "        #resized_im = resize(crop)\n",
    "        resized_im=misc.imresize(show_img, (32,32), interp=\"bilinear\")\n",
    "        \n",
    "        #plt.imshow(resized_im) \n",
    "        #plt.show() \n",
    "        \n",
    "        resized_im=resized_im.reshape(INPUT_SHAPE)\n",
    "        #print(resized_im)\n",
    "        #resized_im =np.expand_dims(resized_im, axis=0)\n",
    "        #label = signnames[predict(model, resized_im)]\n",
    "        label = np.argmax(model.predict(resized_im)[0])\n",
    "        conf = np.max(softmax(model.predict(resized_im)[0]))\n",
    "        # Consider detection only if confidence is larger than threshold\n",
    "        print(\"label=[{}] id={} conf={}\".format(signnames[label],label,conf))\n",
    "        if (conf > CONF_THRES ) and  (label in cir_cls) :\n",
    "            print(\"Draw: label=[{}] id={} conf={}\".format(signnames[label],label,conf))\n",
    "            show_img = draw_bb(show_img, bbox)\n",
    "            # Put label and confidence\n",
    "            cv2.putText(show_img, '{}: {:.2f}'.format(signnames[label], conf), (bbox[0], bbox[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 1, 0), 2)\n",
    "        else:\n",
    "            print('No Draw: label=[{}] id={} conf={}'.format(signnames[label],label, conf))\n",
    "\n",
    "    \n",
    "    show_img=np.uint8(show_img * 255)\n",
    "    plt.imshow(show_img) \n",
    "    plt.show() \n",
    "demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=[End of no passing] id=41 conf=0.16136983036994934\n",
      "label=[Speed limit (100km/h)] id=7 conf=0.43100589513778687\n",
      "label=[Road work] id=25 conf=0.7249883413314819\n",
      "[MoviePy] >>>> Building video ../picture/v-output.mp4\n",
      "[MoviePy] Writing audio in v-outputTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314/314 [00:00<00:00, 406.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] Writing video ../picture/v-output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/426 [00:00<00:51,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=[End of no passing] id=41 conf=0.16136983036994934\n",
      "label=[Speed limit (100km/h)] id=7 conf=0.43100589513778687\n",
      "label=[Road work] id=25 conf=0.7249883413314819\n",
      "label=[End of no passing] id=41 conf=0.31737837195396423\n",
      "label=[Speed limit (100km/h)] id=7 conf=0.4040176570415497\n",
      "label=[Right-of-way at the next intersection] id=11 conf=0.4569477140903473\n",
      "label=[Yield] id=13 conf=0.43297260999679565\n",
      "label=[Keep left] id=39 conf=0.16472744941711426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/426 [00:00<00:46,  9.07it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#实现回调函数 处理每一帧图像\n",
    "def invert_VideoFileClip(image):\n",
    "  \n",
    "    #归一化 非常重要\n",
    "    show_img=(image.copy() / 255.).astype(np.float32)\n",
    "    \n",
    "   \n",
    "    bboxes = find_circles(show_img, mg_ratio=0.4, n_circles=3)\n",
    "    for bbox in bboxes:\n",
    "        \n",
    "        crop = crop_bb(show_img, bbox)\n",
    "        resized_im=cv2.resize(crop,(32,32))\n",
    "\n",
    "        #plt.imshow(resized_im) \n",
    "        #plt.show() \n",
    "\n",
    "        resized_im=resized_im.reshape(INPUT_SHAPE)\n",
    "        #print(resized_im)\n",
    "        #resized_im =np.expand_dims(resized_im, axis=0)\n",
    "        #label = signnames[predict(model, resized_im)]\n",
    "        label = np.argmax(model.predict(resized_im)[0])\n",
    "        conf = np.max(softmax(model.predict(resized_im)[0]))\n",
    "        # Consider detection only if confidence is larger than threshold\n",
    "        print(\"label=[{}] id={} conf={}\".format(signnames[label],label,conf))\n",
    "        if (conf > CONF_THRES ) and  (label in cir_cls) :\n",
    "            print(\"Draw: label=[{}] id={} conf={}\".format(signnames[label],label,conf))\n",
    "            show_img = draw_bb(show_img, bbox)\n",
    "            # Put label and confidence\n",
    "            cv2.putText(show_img, '{}: {:.2f}'.format(signnames[label], conf), (bbox[0], bbox[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 1, 0), 2)\n",
    "            \n",
    "\n",
    "    show_img=np.uint8(show_img * 255)\n",
    "    return show_img\n",
    "\n",
    "clip = VideoFileClip(infile)\n",
    "modifiedClip = clip.fl_image(invert_VideoFileClip)\n",
    "modifiedClip.write_videofile(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
