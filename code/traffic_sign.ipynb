{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "#brew install opencv\n",
    "#pip install opencv-python\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "#pip install moviepy\n",
    "#pip install requests\n",
    "from moviepy.editor import *\n",
    "from matplotlib import pyplot as plt \n",
    "import keras\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "\n",
    "\n",
    "infile=\"../picture/v.mp4\"\n",
    "outfile=\"../picture/v-output.mp4\"\n",
    "\n",
    "'''\n",
    "Code adapted from:\n",
    "https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "\n",
    "'''\n",
    "\n",
    "IMG_SHAPE=[32,32,3]\n",
    "INPUT_SHAPE=[1,32,32,3]\n",
    "L2_LAMBDA = 0.0001   \n",
    "WEIGTHS_PATH=\"../doc/weights_mltscl_dataaug.hdf5\"\n",
    "OUTPUT_DIM=43\n",
    "LR = 0.0001\n",
    "CONF_THRES=0.4\n",
    "\n",
    "# Labels of circlur signs\n",
    "cir_cls = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 16,\n",
    "           17, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42]\n",
    "\n",
    "signnames = read_csv(\"../doc/signnames.csv\").values[:, 1]\n",
    "\n",
    "#print(signnames)\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Compute softmax values for each sets of scores in x.\n",
    "    Ref: https://stackoverflow.com/questions/34968722/softmax-function-python\n",
    "    \"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def build_mltscl():\n",
    "    \"\"\"\n",
    "    Build multiscale CNN. The last layer must be logits instead of softmax.\n",
    "    Return a compiled Keras model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Regularization\n",
    "    l2_reg = keras.regularizers.l2(L2_LAMBDA)\n",
    "\n",
    "    # Build model\n",
    "    inpt = keras.layers.Input(shape=IMG_SHAPE)\n",
    "    conv1 = keras.layers.Convolution2D(\n",
    "        32, (5, 5), padding='same', activation='relu')(inpt)\n",
    "    drop1 = keras.layers.Dropout(rate=0.1)(conv1)\n",
    "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(drop1)\n",
    "\n",
    "    conv2 = keras.layers.Convolution2D(\n",
    "        64, (5, 5), padding='same', activation='relu')(pool1)\n",
    "    drop2 = keras.layers.Dropout(rate=0.2)(conv2)\n",
    "    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(drop2)\n",
    "\n",
    "    conv3 = keras.layers.Convolution2D(\n",
    "        128, (5, 5), padding='same', activation='relu')(pool2)\n",
    "    drop3 = keras.layers.Dropout(rate=0.3)(conv3)\n",
    "    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(drop3)\n",
    "\n",
    "    pool4 = keras.layers.MaxPooling2D(pool_size=(4, 4))(pool1)\n",
    "    pool5 = keras.layers.MaxPooling2D(pool_size=(2, 2))(pool2)\n",
    "\n",
    "    flat1 = keras.layers.Flatten()(pool4)\n",
    "    flat2 = keras.layers.Flatten()(pool5)\n",
    "    flat3 = keras.layers.Flatten()(pool3)\n",
    "\n",
    "    merge = keras.layers.Concatenate(axis=-1)([flat1, flat2, flat3])\n",
    "    dense1 = keras.layers.Dense(1024, activation='relu',\n",
    "                                kernel_regularizer=l2_reg)(merge)\n",
    "    drop4 = keras.layers.Dropout(rate=0.5)(dense1)\n",
    "    output = keras.layers.Dense(\n",
    "        OUTPUT_DIM, activation=None, kernel_regularizer=l2_reg)(drop4)\n",
    "    model = keras.models.Model(inputs=inpt, outputs=output)\n",
    "\n",
    "    # Specify optimizer\n",
    "    adam = keras.optimizers.Adam(\n",
    "        lr=LR, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model=build_mltscl()\n",
    "model.load_weights(WEIGTHS_PATH)\n",
    "#model.summary()\n",
    "\n",
    "def rgb2gray(image):\n",
    "    \"\"\"Convert 3-channel RGB image into grayscale\"\"\"\n",
    "    if image.ndim == 3:\n",
    "        return (0.299 * image[:, :, 0] + 0.587 * image[:, :, 1] +\n",
    "                0.114 * image[:, :, 2])\n",
    "    elif image.ndim == 4:\n",
    "        return (0.299 * image[:, :, :, 0] + 0.587 * image[:, :, :, 1] +\n",
    "                0.114 * image[:, :, :, 2])\n",
    "\n",
    "#识别原型的交通牌\n",
    "def find_circles(img, mg_ratio=0.4, n_circles=1):\n",
    "    \"\"\"\n",
    "    Find circular objects and return bounding boxes in the format\n",
    "    [x1, y1, x2, y2]\n",
    "    \"\"\"\n",
    "    \n",
    "    targetImg = np.copy(img)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    grayImg = np.uint8(rgb2gray(targetImg.copy()))\n",
    "    \n",
    "    # Apply Gaussian blur if needed\n",
    "    #原始值n = 13\n",
    "    n=3\n",
    "    grayImg = cv2.GaussianBlur(grayImg.copy(), (n, n), 0)\n",
    "    \n",
    "    \n",
    "    print(\"rgb2gray(grayImg):\")\n",
    "    plt.imshow(grayImg,cmap=plt.cm.gray)\n",
    "    plt.show() \n",
    "    \n",
    "    \n",
    "    #grayImg = targetImg\n",
    "    # param1 is canny threshold, param2 is circle accumulator threshold\n",
    "    # Set of parameters for GTSDB testing\n",
    "    # (because of different frame size and recording device)\n",
    "    # circles = cv2.HoughCircles(grayImg, cv2.HOUGH_GRADIENT, 1, 200,\n",
    "    #                            param1=60, param2=50, minRadius=5,\n",
    "    #                            maxRadius=100)\n",
    "    \n",
    "    #通过调节minRadius=20,maxRadius=250设置可以检测的车牌大小\n",
    "    circles = cv2.HoughCircles(grayImg, cv2.HOUGH_GRADIENT, 1, 200,\n",
    "                               param1=50, param2=30, minRadius=5,\n",
    "                               maxRadius=30)\n",
    "\n",
    "    bboxes = []\n",
    "    try:\n",
    "        cir = circles.astype(np.uint16)\n",
    "        for c in cir[0, :n_circles]:\n",
    "            r = int(c[2])\n",
    "            mg = int(r * mg_ratio)\n",
    "            bboxes.append([c[0] - r - mg, c[1] - r - mg,\n",
    "                           c[0] + r + mg, c[1] + r + mg])\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    except:\n",
    "        raise\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def draw_bb(img, bbox, color=(255, 255, 255)):\n",
    "    \"\"\"Draw bounding box\"\"\"\n",
    "    cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]),\n",
    "                  color, 2)\n",
    "    return img\n",
    "\n",
    "def crop_bb(img, bbox):\n",
    "    \"\"\"Crop image by specifying bounding box\"\"\"\n",
    "    bb = np.array(bbox)\n",
    "    bb = bb * (bb > 0)\n",
    "    return img[bb[1]:bb[3], bb[0]:bb[2], :]\n",
    "\n",
    "\n",
    "def demo():\n",
    "    \n",
    "    demo_file=\"../picture/traffic_sign.jpg\"\n",
    "    #demo_file=\"../picture/70.jpg\"\n",
    "    #demo_file=\"../picture/12_speed_limit_100.jpg\"\n",
    "    demo_img=misc.imread(demo_file, flatten=False, mode='RGB')\n",
    "    plt.imshow(demo_img) \n",
    "    plt.show() \n",
    "        \n",
    "    bboxes = find_circles(demo_img.copy(), mg_ratio=0.1, n_circles=3)\n",
    "    for bbox in bboxes:\n",
    "        crop = crop_bb(demo_img.copy(), bbox)\n",
    "        print(\"crop_bb:\")\n",
    "        plt.imshow(crop) \n",
    "        plt.show() \n",
    "        #resized_im = resize(crop)\n",
    "        resized_im=misc.imresize(crop, (32,32), interp=\"bilinear\")\n",
    "        resized_im=(resized_im / 255.).astype(np.float32)\n",
    "        \n",
    "        print(\"resized_im:\")\n",
    "        plt.imshow(resized_im) \n",
    "        plt.show() \n",
    "        \n",
    "        resized_im=resized_im.reshape(INPUT_SHAPE)\n",
    "        \n",
    "        label = np.argmax(model.predict(resized_im)[0])\n",
    "        conf = np.max(softmax(model.predict(resized_im)[0]))\n",
    "        # Consider detection only if confidence is larger than threshold\n",
    "        print(\"label=[{}] id={} conf={}\".format(signnames[label],label,conf))\n",
    "        if (conf > CONF_THRES ) and  (label in cir_cls) :\n",
    "            print(\"Draw: label=[{}] id={} conf={}\".format(signnames[label],label,conf))\n",
    "            demo_img = draw_bb(demo_img, bbox)\n",
    "            # Put label and confidence\n",
    "            cv2.putText(demo_img, '{}: {:.2f}'.format(signnames[label], conf), (bbox[0]-200, bbox[1] -10 ),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        else:\n",
    "            print('No Draw: label=[{}] id={} conf={}'.format(signnames[label],label, conf))\n",
    "\n",
    "    \n",
    "    #show_img=np.uint8(show_img * 255)\n",
    "    plt.imshow(demo_img) \n",
    "    plt.show() \n",
    "demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#实现回调函数 处理每一帧图像\n",
    "def invert_VideoFileClip(image):\n",
    "  \n",
    "    #归一化 非常重要\n",
    "    show_img=(image.copy() / 255.).astype(np.float32)\n",
    "    \n",
    "   \n",
    "    bboxes = find_circles(show_img, mg_ratio=0.4, n_circles=3)\n",
    "    for bbox in bboxes:\n",
    "        \n",
    "        crop = crop_bb(show_img, bbox)\n",
    "        \n",
    "        resized_im=misc.imresize(crop, (32,32), interp=\"bilinear\")\n",
    "        resized_im=(resized_im / 255.).astype(np.float32)\n",
    "\n",
    "        resized_im=resized_im.reshape(INPUT_SHAPE)\n",
    "        \n",
    "        label = np.argmax(model.predict(resized_im)[0])\n",
    "        conf = np.max(softmax(model.predict(resized_im)[0]))\n",
    "        # Consider detection only if confidence is larger than threshold\n",
    "        print(\"label=[{}] id={} conf={}\".format(signnames[label],label,conf))\n",
    "        if (conf > CONF_THRES ) and  (label in cir_cls) :\n",
    "            print(\"Draw: label=[{}] id={} conf={}\".format(signnames[label],label,conf))\n",
    "            show_img = draw_bb(show_img, bbox)\n",
    "            # Put label and confidence\n",
    "            cv2.putText(show_img, '{}: {:.2f}'.format(signnames[label], conf), (bbox[0], bbox[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 1, 0), 2)\n",
    "            \n",
    "\n",
    "    show_img=np.uint8(show_img * 255)\n",
    "    return show_img\n",
    "\n",
    "#clip = VideoFileClip(infile)\n",
    "#modifiedClip = clip.fl_image(invert_VideoFileClip)\n",
    "#modifiedClip.write_videofile(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b7c25fc56afb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label=[{}] id={} conf={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b7c25fc56afb>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Load images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSAMPLE_IMG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b7c25fc56afb>\u001b[0m in \u001b[0;36mread_images\u001b[0;34m(path, resize, interp)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mvalid_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".gif\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".tga\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".jpeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".ppm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#测试模型可用性\n",
    "SAMPLE_IMG_DIR = '../picture/traffic_sign_samples/'\n",
    "\n",
    "def read_image(im_name):\n",
    "    \"\"\"Read a single image into numpy array\"\"\"\n",
    "    return misc.imread(im_name, flatten=False, mode='RGB')\n",
    "\n",
    "def read_images(path, resize=False, interp='bilinear'):\n",
    "    \"\"\"\n",
    "    Read all image files in a directory, resize to 32 x 32 pixels if\n",
    "    specified. Return array of images with same format as read from\n",
    "    load_dataset(). Chosen interpolation algorithm may affect the result\n",
    "    (default: bilinear). Images are scaled to [0, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    imgs = []\n",
    "    valid_images = [\".jpg\", \".gif\", \".png\", \".tga\", \".jpeg\", \".ppm\"]\n",
    "    for f in sorted(os.listdir(path)):\n",
    "        ext = os.path.splitext(f)[1]\n",
    "        if ext.lower() not in valid_images:\n",
    "            continue\n",
    "        im = read_image(os.path.join(path, f))\n",
    "        if resize:\n",
    "            im = misc.imresize(im, (32, 32), interp=interp)\n",
    "        im = (im / 255.).astype(np.float32)\n",
    "        imgs.append(im)\n",
    "    return np.array(imgs)\n",
    "\n",
    "def test():\n",
    "    # Load images\n",
    "    images = read_images(path=SAMPLE_IMG_DIR, resize=True, interp='bilinear')\n",
    "    for img in images:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        img=img.reshape(INPUT_SHAPE)    \n",
    "        label = np.argmax(model.predict(img)[0])\n",
    "        conf = np.max(softmax(model.predict(img)[0]))\n",
    "        # Consider detection only if confidence is larger than threshold\n",
    "        print(\"label=[{}] id={} conf={}\".format(signnames[label],label,conf))\n",
    " \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book5",
   "language": "python",
   "name": "book5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
