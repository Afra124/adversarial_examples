{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对比展现原始图片和对抗样本图片\n",
    "def show_images_diff(original_img,original_label,adversarial_img,adversarial_label):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "\n",
    "    #归一化\n",
    "    if original_img.any() > 1.0:\n",
    "        original_img=original_img/255.0\n",
    "    if adversarial_img.any() > 1.0:\n",
    "        adversarial_img=adversarial_img/255.0\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plt.title('Original')\n",
    "    plt.imshow(original_img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.title('Adversarial')\n",
    "    plt.imshow(adversarial_img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.title('Adversarial-Original')\n",
    "    difference = adversarial_img - original_img\n",
    "    #(-1,1)  -> (0,1)\n",
    "    difference=difference / abs(difference).max()/2.0+0.5\n",
    "    plt.imshow(difference,cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘图函数\n",
    "def classify(img, correct_class=None, target_class=None):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 8))\n",
    "    fig.sca(ax1)\n",
    "    p = sess.run(probs, feed_dict={image: img})[0]\n",
    "    ax1.imshow(img)\n",
    "    fig.sca(ax1)\n",
    "    \n",
    "    topk = list(p.argsort()[-10:][::-1])\n",
    "    topprobs = p[topk]\n",
    "    barlist = ax2.bar(range(10), topprobs)\n",
    "    if target_class in topk:\n",
    "        barlist[topk.index(target_class)].set_color('r')\n",
    "    if correct_class in topk:\n",
    "        barlist[topk.index(correct_class)].set_color('g')\n",
    "    plt.sca(ax2)\n",
    "    plt.ylim([0, 1.1])\n",
    "    plt.xticks(range(10),\n",
    "               [imagenet_labels[i][:15] for i in topk],\n",
    "               rotation='vertical')\n",
    "    fig.subplots_adjust(bottom=0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把id转换成可读字符串\n",
    "#参考：https://github.com/tensorflow/models/blob/1af55e018eebce03fb61bba9959a04672536107d/tutorials/image/imagenet/classify_image.py\n",
    "class NodeLookup(object):\n",
    "  \"\"\"Converts integer node ID's to human readable labels.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               label_lookup_path=None,\n",
    "               uid_lookup_path=None):\n",
    "    if not label_lookup_path:\n",
    "      label_lookup_path = 'models/imagenet_2012_challenge_label_map_proto.pbtxt'\n",
    "    if not uid_lookup_path:\n",
    "      uid_lookup_path = 'models/imagenet_synset_to_human_label_map.txt'\n",
    "    self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
    "\n",
    "  def load(self, label_lookup_path, uid_lookup_path):\n",
    "    \"\"\"Loads a human readable English name for each softmax node.\n",
    "    Args:\n",
    "      label_lookup_path: string UID to integer node ID.\n",
    "      uid_lookup_path: string UID to human-readable string.\n",
    "    Returns:\n",
    "      dict from integer node ID to human-readable string.\n",
    "    \"\"\"\n",
    "    if not tf.gfile.Exists(uid_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', uid_lookup_path)\n",
    "    if not tf.gfile.Exists(label_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', label_lookup_path)\n",
    "\n",
    "    # Loads mapping from string UID to human-readable string\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "    uid_to_human = {}\n",
    "    p = re.compile(r'[n\\d]*[ \\S,]*')\n",
    "    for line in proto_as_ascii_lines:\n",
    "      parsed_items = p.findall(line)\n",
    "      uid = parsed_items[0]\n",
    "      human_string = parsed_items[2]\n",
    "      uid_to_human[uid] = human_string\n",
    "\n",
    "    # Loads mapping from string UID to integer node ID.\n",
    "    node_id_to_uid = {}\n",
    "    proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
    "    for line in proto_as_ascii:\n",
    "      if line.startswith('  target_class:'):\n",
    "        target_class = int(line.split(': ')[1])\n",
    "      if line.startswith('  target_class_string:'):\n",
    "        target_class_string = line.split(': ')[1]\n",
    "        node_id_to_uid[target_class] = target_class_string[1:-2]\n",
    "\n",
    "    # Loads the final mapping of integer node ID to human-readable string\n",
    "    node_id_to_name = {}\n",
    "    for key, val in node_id_to_uid.items():\n",
    "      if val not in uid_to_human:\n",
    "        tf.logging.fatal('Failed to locate: %s', val)\n",
    "      name = uid_to_human[val]\n",
    "      node_id_to_name[key] = name\n",
    "\n",
    "    return node_id_to_name\n",
    "\n",
    "  def id_to_string(self, node_id):\n",
    "    if node_id not in self.node_lookup:\n",
    "      return ''\n",
    "    return self.node_lookup[node_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca (score = 0.89233)(id = 169)\n",
      "indri, indris, Indri indri, Indri brevicaudatus (score = 0.00859)(id = 75)\n",
      "lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens (score = 0.00264)(id = 7)\n"
     ]
    }
   ],
   "source": [
    "#加载解码的图像 这里是个大坑 tf提供的imagenet预训练好的模型pb文件中 包含针对图像的预处理环节 即解码jpg文件 这部分没有梯度\n",
    "#需要直接处理解码后的数据\n",
    "imagename=\"../picture/cropped_panda.jpg\"\n",
    "image=None\n",
    "with tf.gfile.Open(imagename, 'rb') as f:\n",
    "    image = np.array(Image.open(f).convert('RGB')).astype(np.float)\n",
    "    image=np.expand_dims(image, axis=0)\n",
    "\n",
    "session=tf.Session()\n",
    "\n",
    "def create_graph(dirname):\n",
    "    with tf.gfile.FastGFile(dirname, 'rb') as f:\n",
    "        graph_def = session.graph_def\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "#从'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'下载并解压到指定路径\n",
    "create_graph(\"models/classify_image_graph_def.pb\")\n",
    "\n",
    "# 初始化参数  非常重要\n",
    "session.run(tf.global_variables_initializer())\n",
    "tensorlist=[n.name for n in session.graph_def.node]\n",
    "\n",
    "\n",
    "softmax_tensor = session.graph.get_tensor_by_name('softmax:0')\n",
    "input_tensor=session.graph.get_tensor_by_name('ExpandDims:0')\n",
    "predictions = session.run(softmax_tensor,\n",
    "                           {input_tensor: image})\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# Creates node ID --> English string lookup.\n",
    "node_lookup = NodeLookup()\n",
    "\n",
    "#top 3\n",
    "top_k = predictions.argsort()[-3:][::-1]\n",
    "for node_id in top_k:\n",
    "    human_string = node_lookup.id_to_string(node_id)\n",
    "    score = predictions[node_id]\n",
    "    print('%s (score = %.5f)(id = %d)' % (human_string, score,node_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Variable:0' shape=(100, 100, 3) dtype=float32_ref>\"] and loss Tensor(\"Neg:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a318d0132044>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/book5/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    406\u001b[0m           \u001b[0;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m           \u001b[0;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Variable:0' shape=(100, 100, 3) dtype=float32_ref>\"] and loss Tensor(\"Neg:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,100,100,3])\n",
    "target = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "#adv为扰动量\n",
    "adv = tf.Variable(tf.ones([100,100,3]),trainable=True,dtype=tf.float32)\n",
    "\n",
    "input_tensor=x+adv\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(target*tf.log(softmax_tensor))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step=optimizer.minimize(loss=cross_entropy,var_list=[adv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "target=288\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_step.run(feed_dict={x: x, target: [target]})\n",
    "    \n",
    "    label=session.run(logits,feed_dict={x:x})\n",
    "    label=np.argmax(label)\n",
    "    \n",
    "    print(\"epoch={} loss={} label={}\".format(epoch,loss,label))\n",
    "    \n",
    "    #如果定向攻击成功\n",
    "    if label == target:\n",
    "        break  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
