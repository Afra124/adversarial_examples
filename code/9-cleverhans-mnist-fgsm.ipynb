{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参考https://github.com/tensorflow/cleverhans/blob/master/cleverhans_tutorials/mnist_tutorial_pytorch.py\n",
    "#加上这些，如果你的python版本是python2.X，你也得按照python3.X那样使用这些函数。\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from tensorflow.python.platform import flags\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.model import CallableModelWrapper\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_pytorch import convert_pytorch_model_to_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义全局变量\n",
    "\n",
    "NB_EPOCHS = 6\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125] Training accuracy: 88.51%\n",
      "[250] Training accuracy: 97.38%\n",
      "[375] Training accuracy: 97.86%\n",
      "[2814] Clean accuracy: 99.05%\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/cleverhans/attacks.py:216: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/cleverhans/attacks_tf.py:62: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/cleverhans/utils_tf.py:37: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Adv accuracy: 2.720%%\n"
     ]
    }
   ],
   "source": [
    "class PytorchMnistModel(nn.Module):\n",
    "  \"\"\" Basic MNIST model from github\n",
    "  https://github.com/rickiepark/pytorch-examples/blob/master/mnist.ipynb\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    super(PytorchMnistModel, self).__init__()\n",
    "    # input is 28x28\n",
    "    # padding=2 for same padding\n",
    "    self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
    "    # feature map size is 14*14 by pooling\n",
    "    # padding=2 for same padding\n",
    "    self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
    "    # feature map size is 7*7 by pooling\n",
    "    self.fc1 = nn.Linear(64 * 7 * 7, 1024)\n",
    "    self.fc2 = nn.Linear(1024, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "    x = x.view(-1, 64 * 7 * 7)  # reshape Variable\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return F.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "def mnist_tutorial(nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                   train_end=-1, test_end=-1, learning_rate=LEARNING_RATE):\n",
    "  # Train a pytorch MNIST model\n",
    "  torch_model = PytorchMnistModel()\n",
    "  if torch.cuda.is_available():\n",
    "    torch_model = torch_model.cuda()\n",
    "  report = AccuracyReport()\n",
    "\n",
    "  train_loader = torch.utils.data.DataLoader(\n",
    "      datasets.MNIST('data', train=True, download=True,\n",
    "                     transform=transforms.ToTensor()),\n",
    "      batch_size=batch_size, shuffle=True)\n",
    "  test_loader = torch.utils.data.DataLoader(\n",
    "      datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "      batch_size=batch_size)\n",
    "\n",
    "  # Truncate the datasets so that our test run more quickly\n",
    "  train_loader.dataset.train_data = train_loader.dataset.train_data[\n",
    "      :train_end]\n",
    "  test_loader.dataset.test_data = test_loader.dataset.test_data[:test_end]\n",
    "\n",
    "  # Train our model\n",
    "  optimizer = optim.Adam(torch_model.parameters(), lr=learning_rate)\n",
    "  train_loss = []\n",
    "\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  step = 0\n",
    "  for _epoch in range(nb_epochs):\n",
    "    for xs, ys in train_loader:\n",
    "      xs, ys = Variable(xs), Variable(ys)\n",
    "      if torch.cuda.is_available():\n",
    "        xs, ys = xs.cuda(), ys.cuda()\n",
    "      optimizer.zero_grad()\n",
    "      preds = torch_model(xs)\n",
    "      loss = F.nll_loss(preds, ys)\n",
    "      loss.backward()  # calc gradients\n",
    "      train_loss.append(loss.data.item())\n",
    "      optimizer.step()  # update gradients\n",
    "\n",
    "      preds_np = preds.data.cpu().numpy()\n",
    "      correct += (np.argmax(preds_np, axis=1) == ys).sum()\n",
    "      total += len(xs)\n",
    "      step += 1\n",
    "      if total % 1000 == 0:\n",
    "        acc = float(correct) / total\n",
    "        print('[%s] Training accuracy: %.2f%%' % (step, acc * 100))\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "  # Evaluate on clean data\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  for xs, ys in test_loader:\n",
    "    xs, ys = Variable(xs), Variable(ys)\n",
    "    if torch.cuda.is_available():\n",
    "      xs, ys = xs.cuda(), ys.cuda()\n",
    "\n",
    "    preds = torch_model(xs)\n",
    "    preds_np = preds.data.cpu().numpy()\n",
    "\n",
    "    correct += (np.argmax(preds_np, axis=1) == ys).sum()\n",
    "    total += len(xs)\n",
    "\n",
    "  acc = float(correct) / total\n",
    "  report.clean_train_clean_eval = acc\n",
    "  print('[%s] Clean accuracy: %.2f%%' % (step, acc * 100))\n",
    "\n",
    "  # We use tf for evaluation on adversarial data\n",
    "  sess = tf.Session()\n",
    "  x_op = tf.placeholder(tf.float32, shape=(None, 1, 28, 28,))\n",
    "\n",
    "  # Convert pytorch model to a tf_model and wrap it in cleverhans\n",
    "  tf_model_fn = convert_pytorch_model_to_tf(torch_model)\n",
    "  cleverhans_model = CallableModelWrapper(tf_model_fn, output_layer='logits')\n",
    "\n",
    "  # Create an FGSM attack\n",
    "  fgsm_op = FastGradientMethod(cleverhans_model, sess=sess)\n",
    "  fgsm_params = {'eps': 0.3,\n",
    "                 'clip_min': 0.,\n",
    "                 'clip_max': 1.}\n",
    "  adv_x_op = fgsm_op.generate(x_op, **fgsm_params)\n",
    "  adv_preds_op = tf_model_fn(adv_x_op)\n",
    "\n",
    "  # Run an evaluation of our model against fgsm\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  for xs, ys in test_loader:\n",
    "    adv_preds = sess.run(adv_preds_op, feed_dict={x_op: xs})\n",
    "    correct += (np.argmax(adv_preds, axis=1) == ys).sum()\n",
    "    total += len(xs)\n",
    "\n",
    "  acc = float(correct) / total\n",
    "  print('Adv accuracy: {:.3f}%%'.format(acc * 100))\n",
    "  report.clean_train_adv_eval = acc\n",
    "  return report\n",
    "\n",
    "\n",
    "def main(_=None):\n",
    "\n",
    "  mnist_tutorial(nb_epochs=NB_EPOCHS,\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 learning_rate=LEARNING_RATE)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book5",
   "language": "python",
   "name": "book5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
